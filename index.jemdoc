# jemdoc: menu{MENU}{index.html}, nofooter
==Dmitry Rybin

~~~
{}{img_left}{images/dima.jpg}{alt text}{179}{239}{}
Dmitry Rybin\n
Ph.D candidate,\n
School of Data Science, \n
CUHK

Email: rybindmitry1 AT gmail DOT com 

[https://scholar.google.com/citations?user=vpfVfgkAAAAJ&hl=en \[Google Scholar\]] 
[https://twitter.com/DmitryRybin1 \[Twitter\]] [https://www.linkedin.com/in/rybindmitry/ \[LinkedIn\]] 
~~~

== research interest
I'm a final year Ph.D student at <a href="https://www.cuhk.edu.cn/en">CUHK</a>, lucky to be supervised by <a href="https://scholar.google.com/citations?user=dW3gcXoAAAAJ&amp;hl=en">Prof. Zhi-Quan (Tom) Luo</a>. I work on Machine Learning for Combinatorial Optimization, LLM Pretraining algorithms, RL training of LLM. I discovered new matrix multiplication algorithms with RL, saving 10% of operations for Causal Attention and XX^T. I am very inspired by scientific contributions done by Google DeepMind and OpenAI, especially: AlphaFold, AlphaTensor, AlphaProof, AlphaEvolve.


== biography
I was born in a small manufacturing city Nizhniy Tagil in Russia. At 16, i learned about Russian National Math Olympiad, got top 6 in it and became a Candidate for [https://www.imo-official.org/ \[IMO\]] Team. At 17, I moved to Moscow to study pure math at the world-class department at <a href="https://math.hse.ru/en/"> HSE</a>, and did research on Homological Algebra, Representation Theory, Combinatorics, and Mathematical Physics under supervision of <a href="https://en.wikipedia.org/wiki/Boris_Feigin">Boris Feigin</a> and <a href="https://scholar.google.ru/citations?user=p_3bjKUAAAAJ&hl=ru">Valery Gritsenko</a>. 

At 19, I won [https://www.imc-math.org.uk/ \[International Math Olympiad (universty level)\]] and got Senior Research Engineer position at Huawei. At 21, i published first pure math preprint and started PhD at CUHK. There I contributed to various large scale projects e.g. optimization of South Korea 5G Network design. Now I live in Hong Kong / Shenzhen and enjoy their fast-pace high-tech and start-up culture.
                    
== Research that I lead or co-lead

[http://arxiv.org/abs/2406.16793 Adam-mini:  Use Fewer Learning Rates To Gain More] \n
*Yushun Zhang\* *, Congliang Chen\*,  Ziniu Li, Tian Ding, Chenwei Wu, Diederik P. Kingma, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun \n
Preprint


[https://arxiv.org/abs/2402.16788 Why Transformers Need Adam: A Hessian Perspective] \n
*Yushun Zhang*, Congliang Chen, Tian Ding, Ziniu Li, Ruoyu Sun, Zhi-Quan Luo \n
NeurIPS 2024


[https://nips.cc/virtual/2022/spotlight/65228 Adam Can Converge Without Any Modification on Update Rules]  \n
*Yushun Zhang*, Congliang Chen, Naichen Shi, Ruoyu Sun,  Zhi-Quan Luo  \n
NeurIPS 2022 


[https://iclr-blog-track.github.io/2022/03/25/does-adam/ Does Adam Converge and When?] \n
*Yushun Zhang*, Congliang Chen,  Zhi-Quan Luo \n
ICLR Blog Track 2022

[https://openreview.net/forum?id=K_MD-PMTLtA When Expressivity Meets Trainability: Fewer than n Neurons Can Work]  \n
Jiawei Zhang\*, *Yushun Zhang\* *, Mingyi Hong, Ruoyu Sun, Zhi-Quan Luo \n
NeurIPS 2021



== Invited Talks

*Oct 2024*: I gave a talk at U of Minnesota, hosted by [https://scholar.google.com/citations?user=qRnP-p0AAAAJ&hl=en Prof. Mingyi Hong]. Thanks Prof. Hong for the invitation!

- Topic: Why Transformers Need Adam: A Hessian Perspective
- Slides can be seen [files/1024_umntalk.pdf here (this is a >40 min version with Adam-mini included)]

*Oct 2024*: I gave a talk at INFORMS Anneal Meeting, Seattle, hosted by [https://scholar.google.com/citations?user=7ubAY0UAAAAJ&hl=en Jianhao Ma]. Thanks Jianhao for the invitation!

- Topic: Why Transformers Need Adam: A Hessian Perspective
- Slides can be seen [files/spectrum_talk_informs.pdf here (this is a 15 min version)]

*Sep 2023*: I gave a talk at Tsinghua University, hosted by [https://scholar.google.com/citations?user=zX7i1EkAAAAJ&hl=en Prof. Jian Li]. Thanks Prof. Li for the invitation!

- Topic: Converge or Diverge? A Story of Adam
- Slides can be seen [files/Adam_talk_Tsinghua.pdf here]



*Jan 2023*: I gave a talk at Google Brain, hosted by [https://scholar.google.nl/citations?user=yyIoQu4AAAAJ&hl=en Dr. Diederik P. Kingma]. Thanks Dr. Kingma for the invitation! 

- Topic: Adam Can Converge Without Any Modification on Update Rules 
- Slides can be seen  [files/Adam_talk_google_short.pdf here]


== Awards (By time)


Duan Yongping Outstanding Resesearch Award (1st place), 2023

Teaching Assistant Award, School of Data Science, 2023

Magna cum laude of SUSTech, 2019

Outstanding graduation thesis, SUSTech, 2019

Scholarship Award for Excellence, Mathematics department, SUSTech (Top 10 students) , 2018












